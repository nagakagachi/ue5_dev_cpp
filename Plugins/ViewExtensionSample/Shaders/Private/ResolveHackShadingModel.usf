// ResolveHackShadingModel.usf.usf

#include "/Engine/Private/Common.ush"
#include "/Engine/Private/DeferredShadingCommon.ush"

// ---------------------------------------------------------------------------------------------------------------------
// PostGBuffer
	SamplerState pass0_sampler_screen;
	Texture2D pass0_tex_gbuffer_b_custom;
	Texture2D pass0_tex_gbuffer_c;

	/*
	DeferredShadingCommon.ush
	float EncodeShadingModelIdAndSelectiveOutputMask(uint ShadingModelId, uint SelectiveOutputMask)
	{
		uint Value = (ShadingModelId & SHADINGMODELID_MASK) | SelectiveOutputMask;
		return (float)Value / (float)0xFF;
	}
	uint DecodeShadingModelId(float InPackedChannel)
	{
		return ((uint)round(InPackedChannel * (float)0xFF)) & SHADINGMODELID_MASK;
	}
	uint DecodeSelectiveOutputMask(float InPackedChannel)
	{
		return ((uint)round(InPackedChannel * (float)0xFF)) & ~SHADINGMODELID_MASK;
	}
	*/

	// EngineのDrawScreenPassを利用し, 自動でDrawRectangle関連のParameterが割り当てられる想定.
	void Pass0_VS(
		in float4 InPosition : ATTRIBUTE0,
		in float2 InTexcoord : ATTRIBUTE1,

		out noperspective float4 OutUVAndScreenPos : TEXCOORD0,
		out float4 OutPosition : SV_POSITION)
	{
		DrawRectangle(InPosition, InTexcoord, OutPosition, OutUVAndScreenPos);
	}

	struct Pass0_PsOut
	{
		float4 pbr_shadingmodel : SV_TARGET0;
		float4 bc_ao			: SV_TARGET1;
	};
	Pass0_PsOut Pass0_PS(
		noperspective float4 UVAndScreenPos : TEXCOORD0,
		float4 OutPosition : SV_POSITION
		)
	{
		Pass0_PsOut ps_output = (Pass0_PsOut)0;
		
		float2 UV = UVAndScreenPos.xy;

		// 先行してShadingModelをチェック.
		float4 gbuffer_b_value = Texture2DSample(pass0_tex_gbuffer_b_custom, pass0_sampler_screen, UV);
		uint shading_model = DecodeShadingModelId(gbuffer_b_value.a);
		uint selective_output_mask = DecodeSelectiveOutputMask(gbuffer_b_value.a);

		// Material側の自前の専用MaterialFunctionでShadingModelを書き換えたピクセルを処理する.
		//	ここでCustomShadingModelは 15 としている.
		const uint k_test_shading_model_id = 15;
		if(k_test_shading_model_id != shading_model)
		{
			discard;// 破棄.
		}
		// バッファ読み取り.
		float4 gbuffer_c_value = Texture2DSample(pass0_tex_gbuffer_c, pass0_sampler_screen, UV);
		
		ps_output.pbr_shadingmodel = gbuffer_b_value;
		ps_output.bc_ao = gbuffer_c_value;
		
		// テスト用のShadingModelのピクセルをUnlit扱いにして書き戻す.
		//	DefaultLitマテリアルで出力ShadingModelをハックしてUnlitではない値(15等)の値にすることでGBufferが書き込まれ、ここで実際にShadingMdelの値をUnlitに書き換えることでPostProcess段階でGBufferのあるUnlitのようにできる.
		ps_output.pbr_shadingmodel.a = EncodeShadingModelIdAndSelectiveOutputMask(SHADINGMODELID_UNLIT, selective_output_mask);
		// 今回はDefaultLitに戻しておく.
		//ps_output.pbr_shadingmodel.a = EncodeShadingModelIdAndSelectiveOutputMask(SHADINGMODELID_DEFAULT_LIT, selective_output_mask);
		// Metallic, Specular, Roughness.
		//ps_output.pbr_shadingmodel.r = 0;
		//ps_output.pbr_shadingmodel.g = 0;
		//ps_output.pbr_shadingmodel.b = 1;

		//ps_output.bc_ao.rgb = float3(1,1,1);// BC書き換え.

		return ps_output;
	}


// ---------------------------------------------------------------------------------------------------------------------
// PrePostprocess
	float pass1_list_shadow_threshold;
	SamplerState pass1_sampler_screen;

	Texture2D pass1_tex_scene_color;
	Texture2D pass1_tex_gbuffer_a;// normal
	Texture2D pass1_tex_gbuffer_b_custom;// pbr shadingmodel. カスタムパスで退避したもとのShadingModelを格納したGBuffer.
	Texture2D pass1_tex_gbuffer_c;// basecolor ao
	uint2 pass1_tex_dimensions;


	// EngineのDrawScreenPassを利用し, 自動でDrawRectangle関連のParameterが割り当てられる想定.
	void Pass1_VS(
		in float4 InPosition : ATTRIBUTE0,
		in float2 InTexcoord : ATTRIBUTE1,

		out noperspective float4 OutUVAndScreenPos : TEXCOORD0,
		out float4 OutPosition : SV_POSITION)
	{
		DrawRectangle(InPosition, InTexcoord, OutPosition, OutUVAndScreenPos);
	}

	float4 Pass1_PS(
		noperspective float4 UVAndScreenPos : TEXCOORD0,
		float4 OutPosition : SV_POSITION
		) : SV_TARGET0
	{
		float2 UV = UVAndScreenPos.xy;

		const float4 gbuffer_b_value = Texture2DSample(pass1_tex_gbuffer_b_custom, pass1_sampler_screen, UV);
		const uint shading_model = DecodeShadingModelId(gbuffer_b_value.a);
		const uint selective_output_mask = DecodeSelectiveOutputMask(gbuffer_b_value.a);
		const float gb_metallic = gbuffer_b_value.r;
		const float gb_specular = gbuffer_b_value.g;
		const float gb_roughness = gbuffer_b_value.b;
		
		float4 scene_color = Texture2DSample(pass1_tex_scene_color, pass1_sampler_screen, UV);
		
		// 疑似ShadingModelフィルタリング.
		const uint k_test_shading_model_id = 15;
		if(shading_model != k_test_shading_model_id)
		{
			return scene_color;// 早期リターン.
		}

		// 該当IDピクセルについてのみ適当なフィルタリングを動作させる.
		const int kernel_radius = 7;
		const float2 pixel_uv_size = 1.0 / float2(pass1_tex_dimensions.x, pass1_tex_dimensions.y);
		
		float3 avg[4];
		float3 avg_sq[4];
		int weight[4];
		for(int i = 0; i < 4; ++i)
		{
			avg[i] = 0;
			avg_sq[i] = 0;
			weight[i] = 0;
		}
		
		for(int j = -kernel_radius; j <= kernel_radius; ++j)
		{
			for(int i = -kernel_radius; i <= kernel_radius; ++i)
			{	
				const float2 sample_uv = UV + pixel_uv_size * float2(i, j);

				// 近傍ピクセルのShadingModelチェック.
				const float4 neighbor_gbuffer_b = Texture2DSample(pass1_tex_gbuffer_b_custom, pass1_sampler_screen, sample_uv);
				const uint neighbor_shading_model = DecodeShadingModelId(neighbor_gbuffer_b.a);
				if(neighbor_shading_model != k_test_shading_model_id)
				{
					continue;
				}

				// 近傍ピクセルのカラー.
				float3 sample_scene_color = Texture2DSample(pass1_tex_scene_color, pass1_sampler_screen, sample_uv).xyz;
				float3 sample_scene_color_sq = sample_scene_color*sample_scene_color;

				// Kuwahara-Filter用の格納領域.
				uint lr_bit = 0;
				lr_bit |= (0 >= i)? (1<<0) : 0;// left
				lr_bit |= (0 <= i)? (1<<1) : 0;// right
				uint region_bit = 0;
				region_bit |= (0 >= j)? (lr_bit << 0) : 0;// up
				region_bit |= (0 <= j)? (lr_bit << 2) : 0;// down
				// left-up, right-up, left-down, right-down.
				for(int ri = 0; 0 < region_bit; ++ri)
				{
					if(region_bit & 0x01)
					{
						avg[ri] += sample_scene_color;// 平均用
						avg_sq[ri] += sample_scene_color_sq;// 二乗の平均用
						weight[ri] += 1;// blend weight
					}
					region_bit = (region_bit >> 1);
				}
			}
		}
		// 平均化.
		for(int i = 0; i < 4; ++i)
		{
			const float region_div = (0 < weight[i])? 1.0 / weight[i] : 1;
			avg[i] *= region_div;
			avg_sq[i] *= region_div;
		}

		// チャンネル別分散とその合計を計算.
		float var[4];
		for(int i = 0; i < 4; ++i)
		{
			const float3 var_rgb = avg_sq[i] - avg[i]*avg[i];// 分散 = 二乗の平均 - 平均の二乗
			var[i] = dot(var_rgb, float3(1,1,1));// チャンネル合計.
		}

		// 分散が最小の領域の平均を採用.
		int min_region_i01 = (var[0] < var[1]) ? 0 : 1;
		int min_region_i23 = (var[2] < var[3]) ? 2 : 3;
		int min_region = (var[min_region_i01] < var[min_region_i23]) ? min_region_i01 : min_region_i23;
		return float4(avg[min_region], 0);

	#if 0
		// デバッグ用.
		if(0.2 > UV.x)
		{
			//return scene_color;
		}
		
		const float4 gbuffer_a_value = Texture2DSample(pass1_tex_gbuffer_a, pass1_sampler_screen, UV);
		const float3 gb_normal = DecodeNormal(gbuffer_a_value.rgb);
		const float4 gbuffer_c_value = Texture2DSample(pass1_tex_gbuffer_c, pass1_sampler_screen, UV);
		const float3 gb_bc = gbuffer_c_value.rgb;

		// lit / bc でライト輝度の抽出
		const bool3 valid_bc = (0.001 < gb_bc);
		const float3 bc_div = select(valid_bc, gb_bc, float3(1,1,1));
		const float3 pseudo_irradiance = scene_color.rgb / bc_div;
		const float lit_luminance = Luminance(pseudo_irradiance);

		const float k_shade_thresh = 0.5;
		const float lit_shade_mask = step(k_shade_thresh, gb_roughness);
		
		// Cast Shadowの検出.
		const float lit_shadow_thres_mask = step(pass1_list_shadow_threshold, lit_luminance);
		const float lit_shadow_mask = min(1.0, lit_shadow_thres_mask + (1.0 - lit_shade_mask));
		
		const float toon_shade_lit = min(lerp(0.05, 1.0, lit_shadow_mask), lerp(0.01, 1.0, lit_shade_mask));
		if(0.5 < UV.x)
		{
			//return float4(1.0-lit_shade_mask, 1.0-lit_shadow_mask, 0, 1);
			//return float4(scene_color.rgb * toon_shade_lit, 1);
		}
		return float4(gb_bc * toon_shade_lit, 1);
	#endif
	}